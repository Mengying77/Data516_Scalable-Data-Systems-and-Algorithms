{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"poker\").config(\"spark.some.config.option\",\"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.7803490162 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# create a Spark dataframe named 'raw_data'\n",
    "start_time = time.time()\n",
    "raw_data = spark.read.csv('s3://516ml/poker_hand.csv',\n",
    "                    header='true', inferSchema='true')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "| s1| c1| s2| c2| s3| c3| s4| c4| s5| c5|Class|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "|  4|  7|  3|  5|  3|  3|  1| 13|  4|  8|    0|\n",
      "|  2|  8|  4|  9|  4|  6|  4|  1|  3|  7|    0|\n",
      "|  3|  6|  1|  3|  2| 11|  3|  9|  2|  3|    1|\n",
      "|  2| 10|  2|  5|  4| 13|  3|  9|  1|  6|    0|\n",
      "|  3|  2|  1|  3|  4|  7|  3|  5|  1| 11|    0|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import when\n",
    "raw_data=raw_data.withColumn(\"Class\",when(raw_data.Class == 0,0.0).otherwise(1.0))\n",
    "cols = [\"s1\",\"c1\",\"s2\", \"c2\", \"s3\", \"c3\", \"s4\", \"c4\", \"s5\", \"c5\", \"Class\"]\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "for col in raw_data.columns:\n",
    "     raw_data= raw_data.withColumn(col,F.col(col).cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "cols = [\"s1\",\"c1\",\"s2\", \"c2\", \"s3\", \"c3\", \"s4\", \"c4\", \"s5\", \"c5\", \"Class\"]\n",
    "\n",
    "imputer=Imputer(inputCols=cols,outputCols=cols)\n",
    "model=imputer.fit(raw_data)\n",
    "raw_data=model.transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Class\")\n",
    "# import the vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "# use the transform method to transform our dataset\n",
    "raw_data=assembler.transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"Scaled_features\")\n",
    "raw_data=standardscaler.fit(raw_data).transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = raw_data.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ones are 319351\n",
      "Percentage of ones are 49.9152841731\n"
     ]
    }
   ],
   "source": [
    "dataset_size=float(train.select(\"Class\").count())\n",
    "numPositives=train.select(\"Class\").where('Class == 1').count()\n",
    "per_ones=(float(numPositives)/float(dataset_size))*100\n",
    "numNegatives=float(dataset_size-numPositives)\n",
    "print('The number of ones are {}'.format(numPositives))\n",
    "print('Percentage of ones are {}'.format(per_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancingRatio = 0.500847158269\n"
     ]
    }
   ],
   "source": [
    "BalancingRatio= numNegatives/dataset_size\n",
    "print('BalancingRatio = {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "train=train.withColumn(\"classWeights\", when(train.Class == 1,BalancingRatio).otherwise(1-BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.77806210518 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(labelCol=\"Class\", featuresCol=\"Scaled_features\",weightCol=\"classWeights\",maxIter=10)\n",
    "model = lr.fit(train)    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "predict_train=model.transform(train)\n",
    "predict_test=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BinaryClassificationEvaluator uses areaUnderROC as the default metric. As of now we will continue with the same\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+\n",
      "|Class|       rawPrediction|prediction|         probability|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "|  0.0|[-0.0187502542082...|       1.0|[0.49531257377779...|\n",
      "|  0.0|[-0.0059606745892...|       1.0|[0.49850983576476...|\n",
      "|  0.0|[-0.0200943090666...|       1.0|[0.49497659176204...|\n",
      "|  0.0|[-0.0133344781022...|       1.0|[0.49666642986900...|\n",
      "|  0.0|[-0.0125512778033...|       1.0|[0.49686222174143...|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select(\"Class\",\"rawPrediction\",\"prediction\",\"probability\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set is 0.502700193809\n",
      "The area under ROC for test set is 0.498407331124\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.aggregationDepth,[2,5,10])\\\n",
    "    .addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.fitIntercept,[False, True])\\\n",
    "    .addGrid(lr.maxIter,[10, 100, 1000])\\\n",
    "    .addGrid(lr.regParam,[0.01, 0.5, 2.0]) \\\n",
    "    .build()\n",
    "\n",
    "# https://spark.apache.org/docs/2.1.0/ml-tuning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 940.947670937 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "start_time = time.time()\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# predict_train=cvModel.transform(train)\n",
    "# predict_test=cvModel.transform(test)\n",
    "# print(\"The area under ROC for train set after CV  is {}\".format(evaluator.evaluate(predict_train)))\n",
    "# print(\"The area under ROC for test set after CV  is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 13)\n"
     ]
    }
   ],
   "source": [
    "print((raw_data.count(), len(raw_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
